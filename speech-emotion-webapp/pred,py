
import numpy as np
import librosa
import tensorflow as tf
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

emotion_categories = ['angry', 'happy', 'sad']

def extract_features(audio_path):
    y, sr = librosa.load(audio_path, sr=44100)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    mfccs = np.mean(mfccs.T, axis=0)
    return mfccs


def predict_emotion(audio_path, model_path):
    model = tf.keras.models.load_model(model_path)
    features = extract_features(audio_path)
    features = features.reshape(1, -1)  # Ensure the input shape is correct
    predictions = model.predict(features)
    predicted_index = np.argmax(predictions)
    predicted_emotion = emotion_categories[predicted_index]
    return predicted_emotion

if __name__ == "__main__":
    audio_file_path = "c:/Users/nikhi/Desktop/Emotion/sad/15b09Ta.wav"
    model_directory = 'C:/Users/nikhi/Desktop/project/speech-emotion-webapp/emotion_modl_lstm.h5'
    emotion = predict_emotion(audio_file_path, model_directory)
    print("Predicted Emotion:", emotion)